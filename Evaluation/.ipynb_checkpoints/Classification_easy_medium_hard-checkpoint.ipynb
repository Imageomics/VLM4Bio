{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_NA(response):\n",
    "    apologetic_flag = True if 'sorry' in response or 'does not have the necessary detail' in response or 'cannot accurately identify' in response or 'Sorry' in response or \"can't provide\" in response or \"cannot provide\" in response or \"does not provide\" in response or \"cannot assist\" in response or \"not possible\" in response or \"unable\" in response or 'unknown' in response or 'not clear' in response or 'not determined' in response or 'not known' in response or 'not provided' in response or 'not mentioned' in response or 'not given' in response or 'not specified' in response or 'may not be visible' in response or 'not visible' in response or 'unfortunately' in response or 'not clearly visible' in response else False\n",
    "    return apologetic_flag\n",
    "\n",
    "def remove_verbose(response, organism='fish'):\n",
    "    response = response.replace('The answer is: ', '')\n",
    "    response = response.replace(f'The {organism} in the image is a ', '')\n",
    "    response = response.replace(f'The {organism} in the image is called', '')\n",
    "    response = response.replace(f'The {organism} in the photo is a', '')\n",
    "    response = response.replace(f'The species and scientific name of the {organism} in the image are', '')\n",
    "    response = response.replace(f'The species in the image is', '')\n",
    "    response = response.replace(f'The species of the {organism} in the image is', '')\n",
    "    response = response.replace(f'The scientific name of the {organism} in the image is', '') \n",
    "    response = response.replace(f'The species of the {organism} in the picture is', '')\n",
    "    response = response.replace(f'The species of the {organism} in the photo is', '')\n",
    "    response = response.replace(f'The species of the {organism} in this picture is','')\n",
    "    response = response.replace(f'The {organism} in the photo is called', '')\n",
    "    return response.strip()\n",
    "\n",
    "def classification_eval_direct(data, model_name, organism='fish', task_type='direct'):\n",
    "    out_dict = {\n",
    "        'Model': model_name,\n",
    "        'Question-type': task_type,\n",
    "        'correct_count': 0,\n",
    "        'correct_ge_count' : 0, # only genus correct, partial\n",
    "        'NA_count' : 0,\n",
    "        'incorrect_count': 0,\n",
    "    }\n",
    "    \n",
    "    for data_idx in range(len(data)):\n",
    "        data_item = data[data_idx]\n",
    "        \n",
    "        gt_sci_name = data_item['target-class']\n",
    "        if gt_sci_name != gt_sci_name:\n",
    "            continue\n",
    "        gt_genus = gt_sci_name.split(' ')[0]\n",
    "\n",
    "        if len(gt_sci_name) == 2:\n",
    "            gt_species = gt_sci_name.split(' ')[1]\n",
    "\n",
    "        response = data_item['output']\n",
    "        response = remove_verbose(response, organism=organism)\n",
    "\n",
    "        # correct\n",
    "        if gt_sci_name.lower() in response.lower():\n",
    "            out_dict['correct_count'] += 1\n",
    "            continue\n",
    "\n",
    "        # partial, correct genus only\n",
    "        if gt_genus.lower() in response.lower():\n",
    "            out_dict['correct_ge_count'] += 1\n",
    "            continue\n",
    "\n",
    "        if check_NA(response.lower()):\n",
    "            out_dict['NA_count'] += 1\n",
    "            continue\n",
    "\n",
    "        out_dict['incorrect_count'] += 1\n",
    "\n",
    "    total = out_dict['correct_count'] + out_dict['correct_ge_count'] + out_dict['NA_count'] + out_dict['incorrect_count']\n",
    "\n",
    "\n",
    "    percnt_out_dict = {\n",
    "        'Model': model_name,\n",
    "        'Question-type': task_type,\n",
    "        'correct_count': out_dict['correct_count']*100/total if total!=0 else 0,\n",
    "        'correct_ge_count' : out_dict['correct_ge_count']*100/total if total!=0 else 0,\n",
    "        'NA_count' : out_dict['NA_count']*100/total if total!=0 else 0,\n",
    "        'incorrect_count': out_dict['incorrect_count']*100/total if total!=0 else 0,\n",
    "    }\n",
    "    print(f'Evaluation completed for {model_name}.')\n",
    "\n",
    "    return out_dict, percnt_out_dict\n",
    "\n",
    "\n",
    "def classification_eval_selection(data, model_name, organism='fish', task_type='direct'):\n",
    "    out_dict = {\n",
    "        'Model': model_name,\n",
    "        'Question-type': task_type,\n",
    "        'correct_count': 0,\n",
    "        'correct_ge_count' : 0, # only genus correct, partial\n",
    "        'NA_count' : 0,\n",
    "        'incorrect_count': 0,\n",
    "    }\n",
    "    \n",
    "    for data_idx in range(len(data)):\n",
    "        data_item = data[data_idx]\n",
    "        \n",
    "        gt_sci_name = data_item['target-class']\n",
    "        if gt_sci_name != gt_sci_name:\n",
    "            continue\n",
    "        gt_genus = gt_sci_name.split(' ')[0]\n",
    "\n",
    "        if len(gt_sci_name) == 2:\n",
    "            gt_species = gt_sci_name.split(' ')[1]\n",
    "\n",
    "        response = data_item['output']\n",
    "    \n",
    "        response = remove_verbose(response, organism=organism)\n",
    "\n",
    "        gt_option = data_item['option-gt']\n",
    "        \n",
    "        # print(f'Ground-truth:{gt_option}', response)\n",
    "\n",
    "        if len(response)==1:\n",
    "            if gt_option.lower() == response.lower():\n",
    "                out_dict['correct_count'] += 1\n",
    "            else:\n",
    "                out_dict['incorrect_count'] += 1\n",
    "            continue\n",
    "\n",
    "        elif response.lower() in ['a)', 'b)', 'c)', 'd)']:\n",
    "            if gt_option.lower() == response.lower()[0]:\n",
    "                out_dict['correct_count'] += 1\n",
    "            else:\n",
    "                out_dict['incorrect_count'] += 1\n",
    "            continue\n",
    "                \n",
    "        # correct\n",
    "        if gt_sci_name.lower() in response.lower():\n",
    "            out_dict['correct_count'] += 1\n",
    "            continue\n",
    "\n",
    "        # partial, correct genus only\n",
    "        if gt_genus.lower() in response.lower():\n",
    "            out_dict['correct_ge_count'] += 1\n",
    "            continue\n",
    "\n",
    "        if check_NA(response.lower()):\n",
    "            out_dict['NA_count'] += 1\n",
    "            continue\n",
    "\n",
    "        out_dict['incorrect_count'] += 1\n",
    "\n",
    "    total = out_dict['correct_count'] + out_dict['correct_ge_count'] + out_dict['NA_count'] + out_dict['incorrect_count']\n",
    "\n",
    "\n",
    "    percnt_out_dict = {\n",
    "        'Model': model_name,\n",
    "        'Question-type': task_type,\n",
    "        'correct_count': out_dict['correct_count']*100/total if total!=0 else 0,\n",
    "        'correct_ge_count' : out_dict['correct_ge_count']*100/total if total!=0 else 0,\n",
    "        'NA_count' : out_dict['NA_count']*100/total if total!=0 else 0,\n",
    "        'incorrect_count': out_dict['incorrect_count']*100/total if total!=0 else 0,\n",
    "    }\n",
    "    print(f'Evaluation completed for {model_name}.')\n",
    "\n",
    "    return out_dict, percnt_out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_evaluation(dataset, task_type, task, organism, start_dir, model_list = None):\n",
    "\n",
    "    model_list = MODEL_NAMES if model_list == None else model_list\n",
    "    \n",
    "    for model_name in model_list:\n",
    "        datalist = []\n",
    "        \n",
    "        for chunkid in range(10):\n",
    "            if organism == 'fish':\n",
    "                some_value = 1034 if chunkid != 9 else 1041\n",
    "            elif organism == 'bird':\n",
    "                some_value = 1109 if chunkid != 9 else 1111\n",
    "            elif organism == 'butterfly':\n",
    "                some_value = 1001 if chunkid != 9 else 1004\n",
    "                \n",
    "            RESULT_FILE_TEMPT = f'{start_dir}/{dataset}/{task}/{task_type}/{task}_{model_name}_{task_type}_num_{some_value}_chunk_{chunkid}.jsonl'\n",
    "            datalist+=read_file(RESULT_FILE_TEMPT)\n",
    "    \n",
    "        print(f'Starting Evaluations for model {model_name} on {len(datalist)} results.')\n",
    "    \n",
    "        if task_type == 'direct':\n",
    "            _, percent_result_dict = classification_eval_direct(data=datalist, model_name=model_name, task_type=task_type, organism=organism)\n",
    "        elif task_type == 'selection':\n",
    "            _, percent_result_dict = classification_eval_selection(data=datalist, model_name=model_name, task_type=task_type, organism=organism)\n",
    "\n",
    "        \n",
    "        writer = jsonlines.open(f'./tables/classification_{task_type}_{organism}.jsonl', mode='a')\n",
    "        writer.write(percent_result_dict)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "\n",
    "def read_file(filepath):\n",
    "    if os.path.exists(filepath) == False:\n",
    "        print(f'{filepath} not found.')\n",
    "        return []\n",
    "\n",
    "    datalist = []\n",
    "\n",
    "    with open(filepath, \"r\", encoding='utf-8') as fh:\n",
    "        for line in fh.readlines():\n",
    "            if line:\n",
    "                try: # if the response writing creates any issue, this try-catch will handle it.\n",
    "                    dict_ = json.loads(line) \n",
    "                except:\n",
    "                    continue\n",
    "                datalist.append(dict_)\n",
    "\n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['gpt-4v',\n",
    "               'llava-v1.5-7b',\n",
    "               'llava-v1.5-13b',\n",
    "               'cogvlm-chat',\n",
    "               'blip-flan-xl',\n",
    "               'blip-flan-xxl',\n",
    "               'minigpt4-vicuna-7B',\n",
    "               'minigpt4-vicuna-13B',\n",
    "               'instruct-flant5xl',\n",
    "               'instruct-flant5xxl',\n",
    "               'instruct-vicuna7b',\n",
    "               'instruct-vicuna13b']\n",
    "\n",
    "DATASETS = ['fish-10k', 'bird', 'butterfly-10k']\n",
    "RESULT_DIRS = ['/projects/ml4science/VLM4Bio/']\n",
    "EVAL_TYPE = ['results']\n",
    "TASK_TYPE= ['direct', 'selection']\n",
    "start_dir = os.path.join(RESULT_DIRS[0], EVAL_TYPE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing evalutations for butterfly-10k dataset and classification task and butterfly organism\n"
     ]
    }
   ],
   "source": [
    "task = 'classification'\n",
    "\n",
    "###### FOR Butterfly-10k ########\n",
    "dataset = DATASETS[2] # 0: fish, 1: bird, 2: butterfly\n",
    "organism = 'butterfly' if dataset=='butterfly-10k' else dataset\n",
    "\n",
    "print(f'Writing evalutations for {dataset} dataset and {task} task and {organism} organism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluations for model gpt-4v on 7635 results.\n",
      "Evaluation completed for gpt-4v.\n",
      "Starting Evaluations for model llava-v1.5-7b on 10013 results.\n",
      "Evaluation completed for llava-v1.5-7b.\n",
      "Starting Evaluations for model llava-v1.5-13b on 10013 results.\n",
      "Evaluation completed for llava-v1.5-13b.\n",
      "Starting Evaluations for model cogvlm-chat on 10013 results.\n",
      "Evaluation completed for cogvlm-chat.\n",
      "Starting Evaluations for model blip-flan-xl on 10013 results.\n",
      "Evaluation completed for blip-flan-xl.\n",
      "Starting Evaluations for model blip-flan-xxl on 10013 results.\n",
      "Evaluation completed for blip-flan-xxl.\n",
      "Starting Evaluations for model minigpt4-vicuna-7B on 10013 results.\n",
      "Evaluation completed for minigpt4-vicuna-7B.\n",
      "Starting Evaluations for model minigpt4-vicuna-13B on 10013 results.\n",
      "Evaluation completed for minigpt4-vicuna-13B.\n",
      "Starting Evaluations for model instruct-flant5xl on 10013 results.\n",
      "Evaluation completed for instruct-flant5xl.\n",
      "Starting Evaluations for model instruct-flant5xxl on 10013 results.\n",
      "Evaluation completed for instruct-flant5xxl.\n",
      "Starting Evaluations for model instruct-vicuna7b on 10013 results.\n",
      "Evaluation completed for instruct-vicuna7b.\n",
      "Starting Evaluations for model instruct-vicuna13b on 10013 results.\n",
      "Evaluation completed for instruct-vicuna13b.\n"
     ]
    }
   ],
   "source": [
    "task_type = TASK_TYPE[0] # 0: direct, 1: selection\n",
    "write_evaluation(dataset=dataset, task_type=task_type, task=task, start_dir=start_dir, organism=organism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluations for model gpt-4v on 10013 results.\n",
      "Evaluation completed for gpt-4v.\n",
      "Starting Evaluations for model llava-v1.5-7b on 10013 results.\n",
      "Evaluation completed for llava-v1.5-7b.\n",
      "Starting Evaluations for model llava-v1.5-13b on 10013 results.\n",
      "Evaluation completed for llava-v1.5-13b.\n",
      "Starting Evaluations for model cogvlm-chat on 10013 results.\n",
      "Evaluation completed for cogvlm-chat.\n",
      "Starting Evaluations for model blip-flan-xl on 10013 results.\n",
      "Evaluation completed for blip-flan-xl.\n",
      "Starting Evaluations for model blip-flan-xxl on 10013 results.\n",
      "Evaluation completed for blip-flan-xxl.\n",
      "Starting Evaluations for model minigpt4-vicuna-7B on 10013 results.\n",
      "Evaluation completed for minigpt4-vicuna-7B.\n",
      "Starting Evaluations for model minigpt4-vicuna-13B on 10013 results.\n",
      "Evaluation completed for minigpt4-vicuna-13B.\n",
      "Starting Evaluations for model instruct-flant5xl on 10013 results.\n",
      "Evaluation completed for instruct-flant5xl.\n",
      "Starting Evaluations for model instruct-flant5xxl on 10013 results.\n",
      "Evaluation completed for instruct-flant5xxl.\n",
      "Starting Evaluations for model instruct-vicuna7b on 10013 results.\n",
      "Evaluation completed for instruct-vicuna7b.\n",
      "Starting Evaluations for model instruct-vicuna13b on 10013 results.\n",
      "Evaluation completed for instruct-vicuna13b.\n"
     ]
    }
   ],
   "source": [
    "task_type = TASK_TYPE[1] # 0: direct, 1: selection\n",
    "write_evaluation(dataset=dataset, task_type=task_type, task=task, start_dir=start_dir, organism=organism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "PROMPT_MODELS = ['gpt-4v', 'llava-v1.5-7b', 'llava-v1.5-13b', 'cogvlm-chat', 'blip-flan-xl', 'blip-flan-xxl']\n",
    "MODEL_NAMES = ['gpt-4v',\n",
    "               'llava-v1.5-7b',\n",
    "               'llava-v1.5-13b',\n",
    "               'cogvlm-chat',\n",
    "               'blip-flan-xl',\n",
    "               'blip-flan-xxl',\n",
    "               'minigpt4-vicuna-7B',\n",
    "               'minigpt4-vicuna-13B',\n",
    "               'instruct-flant5xl',\n",
    "               'instruct-flant5xxl',\n",
    "               'instruct-vicuna7b',\n",
    "               'instruct-vicuna13b']\n",
    "# PROMPT_MODELS = MODEL_NAMES\n",
    "\n",
    "def classification_tables(filename, model_lists=MODEL_NAMES, full_display=False):\n",
    "\n",
    "    # Initialize empty lists to store data\n",
    "    model_list = []\n",
    "    question_type_list = []\n",
    "    correct_count_list = []\n",
    "    correct_ge_count_list = []\n",
    "    na_count_list = []\n",
    "    incorrect_count_list = []\n",
    "    \n",
    "    # Read the JSON lines file line by line\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            if data['Model'] not in model_lists:\n",
    "                continue\n",
    "            model_list.append(data['Model'])\n",
    "            question_type_list.append(data['Question-type'])\n",
    "            correct_count_list.append('{:.2f}'.format(data['correct_count']))\n",
    "            correct_ge_count_list.append('{:.2f}'.format(data['correct_ge_count']))\n",
    "            na_count_list.append('{:.2f}'.format(data['NA_count']))\n",
    "            incorrect_count_list.append('{:.2f}'.format(data['incorrect_count']))\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Models': model_list,\n",
    "        'Question-type': question_type_list,\n",
    "        'correct_count': correct_count_list,\n",
    "        'correct_ge_count': correct_ge_count_list,\n",
    "        'NA_count': na_count_list,\n",
    "        'incorrect_count': incorrect_count_list\n",
    "    })\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    if full_display==False:\n",
    "        display(df)\n",
    "\n",
    "    return df[['correct_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t###### Butterfly ######\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Question-type</th>\n",
       "      <th>correct_count</th>\n",
       "      <th>correct_ge_count</th>\n",
       "      <th>NA_count</th>\n",
       "      <th>incorrect_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4v</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>98.17</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llava-v1.5-7b</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llava-v1.5-13b</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cogvlm-chat</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.63</td>\n",
       "      <td>99.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blip-flan-xl</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blip-flan-xxl</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>minigpt4-vicuna-7B</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.90</td>\n",
       "      <td>13.13</td>\n",
       "      <td>85.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>minigpt4-vicuna-13B</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.86</td>\n",
       "      <td>98.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>instruct-flant5xl</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instruct-flant5xxl</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>instruct-vicuna7b</td>\n",
       "      <td>direct</td>\n",
       "      <td>9.94</td>\n",
       "      <td>11.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>78.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>instruct-vicuna13b</td>\n",
       "      <td>direct</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Models Question-type correct_count correct_ge_count NA_count  \\\n",
       "0                gpt-4v        direct          0.04             0.09    98.17   \n",
       "1         llava-v1.5-7b        direct          0.05             0.25     0.00   \n",
       "2        llava-v1.5-13b        direct          0.00             0.05     0.00   \n",
       "3           cogvlm-chat        direct          0.01             0.27     0.63   \n",
       "4          blip-flan-xl        direct          0.00             0.00     0.00   \n",
       "5         blip-flan-xxl        direct          0.00             0.00     0.00   \n",
       "6    minigpt4-vicuna-7B        direct          0.07             0.90    13.13   \n",
       "7   minigpt4-vicuna-13B        direct          0.01             0.06     1.86   \n",
       "8     instruct-flant5xl        direct          0.00             0.00     0.00   \n",
       "9    instruct-flant5xxl        direct          0.00             0.00     0.00   \n",
       "10    instruct-vicuna7b        direct          9.94            11.78     0.00   \n",
       "11   instruct-vicuna13b        direct          0.00             0.00     0.00   \n",
       "\n",
       "   incorrect_count  \n",
       "0             1.70  \n",
       "1            99.70  \n",
       "2            99.95  \n",
       "3            99.09  \n",
       "4           100.00  \n",
       "5           100.00  \n",
       "6            85.90  \n",
       "7            98.07  \n",
       "8           100.00  \n",
       "9           100.00  \n",
       "10           78.28  \n",
       "11          100.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct_count\n",
       "0           0.04\n",
       "1           0.05\n",
       "2           0.00\n",
       "3           0.01\n",
       "4           0.00\n",
       "5           0.00\n",
       "6           0.07\n",
       "7           0.01\n",
       "8           0.00\n",
       "9           0.00\n",
       "10          9.94\n",
       "11          0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Question-type</th>\n",
       "      <th>correct_count</th>\n",
       "      <th>correct_ge_count</th>\n",
       "      <th>NA_count</th>\n",
       "      <th>incorrect_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4v</td>\n",
       "      <td>selection</td>\n",
       "      <td>28.91</td>\n",
       "      <td>5.75</td>\n",
       "      <td>54.85</td>\n",
       "      <td>10.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llava-v1.5-7b</td>\n",
       "      <td>selection</td>\n",
       "      <td>50.24</td>\n",
       "      <td>24.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llava-v1.5-13b</td>\n",
       "      <td>selection</td>\n",
       "      <td>44.58</td>\n",
       "      <td>19.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cogvlm-chat</td>\n",
       "      <td>selection</td>\n",
       "      <td>36.45</td>\n",
       "      <td>28.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blip-flan-xl</td>\n",
       "      <td>selection</td>\n",
       "      <td>25.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blip-flan-xxl</td>\n",
       "      <td>selection</td>\n",
       "      <td>28.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>minigpt4-vicuna-7B</td>\n",
       "      <td>selection</td>\n",
       "      <td>33.06</td>\n",
       "      <td>20.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>45.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>minigpt4-vicuna-13B</td>\n",
       "      <td>selection</td>\n",
       "      <td>28.90</td>\n",
       "      <td>22.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>48.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>instruct-flant5xl</td>\n",
       "      <td>selection</td>\n",
       "      <td>25.28</td>\n",
       "      <td>14.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instruct-flant5xxl</td>\n",
       "      <td>selection</td>\n",
       "      <td>36.67</td>\n",
       "      <td>30.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>instruct-vicuna7b</td>\n",
       "      <td>selection</td>\n",
       "      <td>41.70</td>\n",
       "      <td>23.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>instruct-vicuna13b</td>\n",
       "      <td>selection</td>\n",
       "      <td>34.48</td>\n",
       "      <td>21.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Models Question-type correct_count correct_ge_count NA_count  \\\n",
       "0                gpt-4v     selection         28.91             5.75    54.85   \n",
       "1         llava-v1.5-7b     selection         50.24            24.31     0.00   \n",
       "2        llava-v1.5-13b     selection         44.58            19.63     0.00   \n",
       "3           cogvlm-chat     selection         36.45            28.24     0.00   \n",
       "4          blip-flan-xl     selection         25.14             0.00     0.00   \n",
       "5         blip-flan-xxl     selection         28.88             0.00     0.00   \n",
       "6    minigpt4-vicuna-7B     selection         33.06            20.32     1.04   \n",
       "7   minigpt4-vicuna-13B     selection         28.90            22.26     0.20   \n",
       "8     instruct-flant5xl     selection         25.28            14.07     0.00   \n",
       "9    instruct-flant5xxl     selection         36.67            30.73     0.00   \n",
       "10    instruct-vicuna7b     selection         41.70            23.09     0.00   \n",
       "11   instruct-vicuna13b     selection         34.48            21.52     0.00   \n",
       "\n",
       "   incorrect_count  \n",
       "0            10.49  \n",
       "1            25.45  \n",
       "2            35.78  \n",
       "3            35.30  \n",
       "4            74.86  \n",
       "5            71.12  \n",
       "6            45.58  \n",
       "7            48.64  \n",
       "8            60.65  \n",
       "9            32.60  \n",
       "10           35.21  \n",
       "11           44.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct_count\n",
       "0          28.91\n",
       "1          50.24\n",
       "2          44.58\n",
       "3          36.45\n",
       "4          25.14\n",
       "5          28.88\n",
       "6          33.06\n",
       "7          28.90\n",
       "8          25.28\n",
       "9          36.67\n",
       "10         41.70\n",
       "11         34.48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\t\\t\\t\\t\\t###### Butterfly ######\")\n",
    "df_eval = classification_tables('./tables/classification_direct_butterfly.jsonl', model_lists=MODEL_NAMES)\n",
    "display(df_eval)\n",
    "df_eval = classification_tables('./tables/classification_selection_butterfly.jsonl', model_lists=MODEL_NAMES)\n",
    "display(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
